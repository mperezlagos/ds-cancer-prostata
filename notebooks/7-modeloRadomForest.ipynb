{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.91      0.95        99\n",
      "         1.0       0.98      1.00      0.99       430\n",
      "\n",
      "    accuracy                           0.98       529\n",
      "   macro avg       0.99      0.95      0.97       529\n",
      "weighted avg       0.98      0.98      0.98       529\n",
      "\n",
      "[[ 90   9]\n",
      " [  0 430]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = '../data/processed/df_cancer_prostata_processed.csv'\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Identificar características y variable objetivo\n",
    "X = df.drop(columns=['SOBREVIVE'])\n",
    "y = df['SOBREVIVE']\n",
    "\n",
    "# Identificar variables categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocesamiento de las características\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# División del dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creación y entrenamiento del modelo\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones y evaluación del modelo\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Reporte de clasificación y matriz de confusión\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(report)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del Modelo de Predicción\n",
    "\n",
    "### Reporte de Clasificación\n",
    "\n",
    "Precisión: 1.00 para la clase 0 (no sobrevive) y 0.99 para la clase 1 (sobrevive).\n",
    "\n",
    "Recall: 0.94 para la clase 0 y 1.00 para la clase 1.\n",
    "\n",
    "F1-Score: 0.97 para la clase 0 y 0.99 para la clase 1.\n",
    "\n",
    "Exactitud Global: 0.99\n",
    "\n",
    "Matriz de Confusión\n",
    "\n",
    "Clase 0 (no sobrevive): 90 verdaderos negativos y 9 falsos positivos.\n",
    "\n",
    "Clase 1 (sobrevive): 0 falsos negativos y 430 verdaderos positivos.\n",
    "\n",
    "El modelo Random Forest muestra un rendimiento excelente con una precisión y recall casi perfectos. Esto indica que el modelo es muy bueno prediciendo la supervivencia de los pacientes con cáncer de próstata en este dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9557491264249298, 0.010325122725763775)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Validación cruzada con 5 folds\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Mostrar los resultados de la validación cruzada\n",
    "cv_scores.mean(), cv_scores.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados de la Validación Cruzada\n",
    "\n",
    "Precisión media: 0.955\n",
    "\n",
    "Desviación estándar: 0.010\n",
    "\n",
    "Estos resultados muestran que el modelo mantiene un rendimiento consistentemente alto en diferentes divisiones del dataset, lo cual indica una buena generalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/cancer_survival_model-RandomForestClassifier.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "# Definir los hiperparámetros para la búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros y el mejor score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "import joblib\n",
    "joblib.dump(grid_search.best_estimator_, '../models/cancer_survival_model-RandomForestClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetro                   Mejor Valor\n",
      "-----------------------------  -------------\n",
      "classifier__max_depth                     30\n",
      "classifier__min_samples_leaf               1\n",
      "classifier__min_samples_split              2\n",
      "classifier__n_estimators                 100\n",
      "\n",
      "Mejor Score: 0.9825059101654846\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Convertir best_params en una lista de listas para tabular\n",
    "params_table = [[key, value] for key, value in best_params.items()]\n",
    "\n",
    "# Imprimir best_params con tabulate\n",
    "print(tabulate(params_table, headers=[\"Hiperparámetro\", \"Mejor Valor\"]))\n",
    "\n",
    "# Mostrar el mejor score\n",
    "print(f\"\\nMejor Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características: 2642\n",
      "Número de importancias: 2230\n",
      "Error: Las longitudes de 'feature_names' e 'importancias' no coinciden.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "modelo = joblib.load('../models/cancer_survival_model-RandomForestClassifier.pkl')\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importancias = modelo.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Codificar y escalar características para obtener nombres de características transformadas\n",
    "preprocessor = modelo.named_steps['preprocessor']\n",
    "preprocessor.fit(X)\n",
    "\n",
    "# Obtener los nombres de las columnas transformadas\n",
    "onehot_columns = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_features)\n",
    "feature_names = numeric_features.tolist() + onehot_columns.tolist()\n",
    "\n",
    "# Verificar la longitud de feature_names e importancias\n",
    "print(f'Número de características: {len(feature_names)}')\n",
    "print(f'Número de importancias: {len(importancias)}')\n",
    "\n",
    "# Asegurarse de que las longitudes coincidan\n",
    "if len(feature_names) == len(importancias):\n",
    "    # Crear un DataFrame para visualizar las importancias\n",
    "    importancia_df = pd.DataFrame({\n",
    "        'Característica': feature_names,\n",
    "        'Importancia': importancias\n",
    "    })\n",
    "\n",
    "    # Ordenar por importancia\n",
    "    importancia_df = importancia_df.sort_values(by='Importancia', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Visualizar las importancias\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importancia', y='Característica', data=importancia_df.head(20))\n",
    "    plt.title('Importancia de las Características (Top 20)')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error: Las longitudes de 'feature_names' e 'importancias' no coinciden.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características: 2642\n",
      "Número de importancias: 2230\n",
      "Características y sus importancias:\n",
      "COD_TOPOLOGIA: 0.0\n",
      "DIAS_HASTA_INICIO_TRATAMIENTO: 0.019809539491746835\n",
      "DIAS_DESDE_NACIMIENTO_A_DIAGNO: 0.020172654608012118\n",
      "DIAS_DESDE_INGRESO_A_DIAGNO: 0.012202379107943636\n",
      "DIAS_DESDE_DIAGNO_A_COMITE: 0.010118934635609525\n",
      "DIAS_DESDE_TOM_MUESTRA_A_DIAGNO: 0.00869965034599194\n",
      "DIAS_DESDE_DIAGNO_TRATAMIENTO_2: 0.010021698144805953\n",
      "DIAS_DESDE_TRATAMIENTO_1_A_TRATAMIENTO_2: 0.013368726848596116\n",
      "DIAS_TRATAMIENTO_1: 0.0213816545314099\n",
      "DIAS_TRATAMIENTO_2: 0.01143864846517943\n",
      "Longitud de feature_names: 2642\n",
      "Longitud de importancias: 2230\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cargar datos\n",
    "file_path = '../data/processed/df_cancer_prostata_processed.csv'  # Actualiza la ruta del archivo\n",
    "df = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Identificar características y variable objetivo\n",
    "X = df.drop(columns=['SOBREVIVE'])\n",
    "y = df['SOBREVIVE']\n",
    "\n",
    "# Identificar variables categóricas y numéricas\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Preprocesamiento de las características\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# División del dataset en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ajustar manualmente los hiperparámetros del modelo Random Forest\n",
    "clf_manual = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('classifier', RandomForestClassifier(\n",
    "                                 n_estimators=200,\n",
    "                                 max_depth=20,\n",
    "                                 min_samples_split=5,\n",
    "                                 min_samples_leaf=2,\n",
    "                                 random_state=42))])\n",
    "\n",
    "# Entrenar el modelo\n",
    "clf_manual.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "joblib.dump(clf_manual, '../models/cancer_survival_model-RandomForestClassifier.pkl')\n",
    "\n",
    "# Cargar el modelo guardado\n",
    "modelo = joblib.load('../models/cancer_survival_model-RandomForestClassifier.pkl')\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importancias = modelo.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Codificar y escalar características para obtener nombres de características transformadas\n",
    "preprocessor = modelo.named_steps['preprocessor']\n",
    "preprocessor.fit(X)\n",
    "\n",
    "# Obtener los nombres de las columnas transformadas\n",
    "onehot_columns = preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(categorical_features)\n",
    "feature_names = numeric_features.tolist() + onehot_columns.tolist()\n",
    "\n",
    "# Verificar la longitud de feature_names e importancias\n",
    "print(f'Número de características: {len(feature_names)}')\n",
    "print(f'Número de importancias: {len(importancias)}')\n",
    "\n",
    "# Mostrar algunas características y sus importancias para diagnosticar\n",
    "print(\"Características y sus importancias:\")\n",
    "for name, importance in zip(feature_names[:10], importancias[:10]):\n",
    "    print(f\"{name}: {importance}\")\n",
    "\n",
    "# Si las longitudes no coinciden, imprimir las longitudes exactas\n",
    "if len(feature_names) != len(importancias):\n",
    "    print(f\"Longitud de feature_names: {len(feature_names)}\")\n",
    "    print(f\"Longitud de importancias: {len(importancias)}\")\n",
    "else:\n",
    "    # Crear un DataFrame para visualizar las importancias\n",
    "    importancia_df = pd.DataFrame({\n",
    "        'Característica': feature_names,\n",
    "        'Importancia': importancias\n",
    "    })\n",
    "\n",
    "    # Ordenar por importancia\n",
    "    importancia_df = importancia_df.sort_values(by='Importancia', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Visualizar las importancias\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importancia', y='Característica', data=importancia_df.head(20))\n",
    "    plt.title('Importancia de las Características (Top 20)')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
